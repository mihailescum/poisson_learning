{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import poissonlearning as pl\n",
    "import graphlearning as gl\n",
    "\n",
    "import storage\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"mnist\"\n",
    "dataset_metric = \"vae\"\n",
    "experiments = storage.load_results(name=\"real_data\", folder=\"../results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>8.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.301 (0.28)</td>\n",
       "      <td>71.994 (0.79)</td>\n",
       "      <td>66.042 (0.89)</td>\n",
       "      <td>62.585 (1.08)</td>\n",
       "      <td>60.251 (1.05)</td>\n",
       "      <td>57.655 (0.78)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.454 (2.63)</td>\n",
       "      <td>83.635 (2.93)</td>\n",
       "      <td>79.458 (3.03)</td>\n",
       "      <td>76.657 (3.26)</td>\n",
       "      <td>74.689 (3.46)</td>\n",
       "      <td>72.530 (3.43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92.101 (0.81)</td>\n",
       "      <td>89.606 (1.06)</td>\n",
       "      <td>87.434 (1.19)</td>\n",
       "      <td>85.596 (1.13)</td>\n",
       "      <td>84.384 (1.13)</td>\n",
       "      <td>83.040 (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>92.673 (0.78)</td>\n",
       "      <td>90.898 (1.10)</td>\n",
       "      <td>89.163 (1.27)</td>\n",
       "      <td>87.643 (1.40)</td>\n",
       "      <td>86.480 (1.32)</td>\n",
       "      <td>85.388 (1.43)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              2.0            3.0            4.0            5.0            6.0  \\\n",
       "1   80.301 (0.28)  71.994 (0.79)  66.042 (0.89)  62.585 (1.08)  60.251 (1.05)   \n",
       "2   88.454 (2.63)  83.635 (2.93)  79.458 (3.03)  76.657 (3.26)  74.689 (3.46)   \n",
       "5   92.101 (0.81)  89.606 (1.06)  87.434 (1.19)  85.596 (1.13)  84.384 (1.13)   \n",
       "10  92.673 (0.78)  90.898 (1.10)  89.163 (1.27)  87.643 (1.40)  86.480 (1.32)   \n",
       "\n",
       "              8.0  \n",
       "1   57.655 (0.78)  \n",
       "2   72.530 (3.43)  \n",
       "5   83.040 (0.98)  \n",
       "10  85.388 (1.43)  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_all = list(set((ex[\"p\"] for ex in experiments if ex[\"dataset\"] == dataset and ex[\"dataset_metric\"] == dataset_metric)))\n",
    "results_table = pd.DataFrame()\n",
    "for p in p_all:\n",
    "    labels_per_class_all = list(set((ex[\"labels_per_class\"] for ex in experiments if np.isclose(ex[\"p\"], p) and ex[\"dataset\"] == dataset and ex[\"dataset_metric\"] == dataset_metric)))\n",
    "    results_p = pd.Series(index=labels_per_class_all, name=p, dtype=\"object\")\n",
    "    for num_labels in labels_per_class_all:\n",
    "        selected_experiments = list(\n",
    "            filter(\n",
    "                lambda x: \n",
    "                    np.isclose(x[\"p\"], p) \n",
    "                    and np.all(np.isclose(x[\"labels_per_class\"], num_labels))\n",
    "                    and x[\"dataset\"] == dataset,\n",
    "                experiments\n",
    "            )\n",
    "        )\n",
    "        def _compute_accuracy(experiment):\n",
    "            prob = experiment[\"solution\"].drop(columns=[\"x\", \"y\", \"true_labels\"]).to_numpy()\n",
    "            scores = prob - np.min(prob)\n",
    "            scores = scores / np.max(scores)\n",
    "\n",
    "            # Check if scores are similarity or distance\n",
    "            pred_labels = np.argmax(scores, axis=1)\n",
    "            accuracy = gl.ssl.ssl_accuracy(experiment[\"solution\"][\"true_labels\"], pred_labels, experiment[\"labels_per_class\"] * 10)\n",
    "            return accuracy\n",
    "        accuracy = [_compute_accuracy(ex) for ex in selected_experiments]\n",
    "        accuracy_mean = np.mean(accuracy)\n",
    "        accuracy_std = np.std(accuracy)\n",
    "        results_p[num_labels] = f\"{accuracy_mean:.3f} ({accuracy_std:.2f})\"\n",
    "\n",
    "    def _extend_results(results_table, new_entries):\n",
    "        new_index = np.union1d(results_table.index, new_entries.index)\n",
    "        results_table = results_table.reindex(new_index)\n",
    "        new_entries = new_entries.reindex(new_index)\n",
    "        results_table[new_entries.name] = new_entries\n",
    "        return results_table\n",
    "\n",
    "    results_table = _extend_results(results_table, results_p)\n",
    "results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "{} &             1  &             2  &             5  &             10 \\\\\n",
      "\\midrule\n",
      "2.0 &  80.301 (0.28) &  88.454 (2.63) &  92.101 (0.81) &  92.673 (0.78) \\\\\n",
      "3.0 &  71.994 (0.79) &  83.635 (2.93) &  89.606 (1.06) &  90.898 (1.10) \\\\\n",
      "4.0 &  66.042 (0.89) &  79.458 (3.03) &  87.434 (1.19) &  89.163 (1.27) \\\\\n",
      "5.0 &  62.585 (1.08) &  76.657 (3.26) &  85.596 (1.13) &  87.643 (1.40) \\\\\n",
      "6.0 &  60.251 (1.05) &  74.689 (3.46) &  84.384 (1.13) &  86.480 (1.32) \\\\\n",
      "8.0 &  57.655 (0.78) &  72.530 (3.43) &  83.040 (0.98) &  85.388 (1.43) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results_table.T.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0309fd4d8093f233da82b79409fbfbf31049f6fad33a75d9435ce0e16e3f1f61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
